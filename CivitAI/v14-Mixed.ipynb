{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c7a0ad4f5744c6b975b4be03450aea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b91a8602ac444a72a01f0f40342cb5a7",
              "IPY_MODEL_6afad3f66c4d49f0b1a286bf74ad6f77",
              "IPY_MODEL_a50f70a22cd941808d77fe9884b02430"
            ],
            "layout": "IPY_MODEL_20c858dcfa87437aa063fa537d38ad19"
          }
        },
        "b91a8602ac444a72a01f0f40342cb5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a511493796154924abb34ff95315461b",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f7ff44349e43aca7a9f258eec938c6",
            "value": " 14%"
          }
        },
        "6afad3f66c4d49f0b1a286bf74ad6f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51248ebc8a5f4b5dbec279ea8ea74350",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1875646c2316432eba13625910a5541a",
            "value": 10
          }
        },
        "a50f70a22cd941808d77fe9884b02430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c06e0067e6b4387a59a0d81e4d46576",
            "placeholder": "​",
            "style": "IPY_MODEL_87d0ba28054b4da5aec4c11c777cd284",
            "value": " 10/70 [00:09&lt;00:53,  1.12it/s]"
          }
        },
        "20c858dcfa87437aa063fa537d38ad19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a511493796154924abb34ff95315461b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f7ff44349e43aca7a9f258eec938c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51248ebc8a5f4b5dbec279ea8ea74350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1875646c2316432eba13625910a5541a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c06e0067e6b4387a59a0d81e4d46576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d0ba28054b4da5aec4c11c777cd284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathotaGamma/AI/blob/main/CivitAI/v14-Mixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drive\n",
        "print(\"Google Driveを使用すると\")\n",
        "print(\"画像が一枚生成されるごとに保存されます。\")\n",
        "drive_use = input(\"Google Driveを使用しますか？ (y/n): \").strip().lower() == \"y\"\n",
        "if drive_use:\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  # マウントポイント\n",
        "  mount_point = '/content/drive'\n",
        "\n",
        "  # Driveがマウントされているか確認\n",
        "  if not os.path.exists(mount_point):\n",
        "    print(\"Google Driveに接続されていません。接続しますか？ (y/n)\")\n",
        "    connect_drive = input().strip().lower()\n",
        "    if connect_drive == 'y':\n",
        "      drive.mount(mount_point)\n",
        "      print(\"Google Driveに接続しました。\")\n",
        "    else:\n",
        "      print(\"Google Driveへの接続をスキップしました。\")\n",
        "      drive_use = False\n",
        "\n",
        "if drive_use:\n",
        "  print(\"保存する「ディレクトリ」のパスを入力してください。\")\n",
        "  print(\"(例: /content/drive/MyDrive/Colab Notebooks/your_dir)\")\n",
        "  print(\"※指定したディレクトリに追加で階層が生成されます(timestamp)。\")\n",
        "  print(\"保存しない場合は空欄で\")\n",
        "  drive_save = input(\"Path or Empty: \")\n",
        "  if drive_save == \"\":\n",
        "    drive_use = False\n",
        "\n",
        "# ---モード選択---\n",
        "print(\"=== モード選択 ===\")\n",
        "print(\"1: Hugging Faceで画像生成\")\n",
        "print(\"2: CivitAI（モデルDL / safetensors変換）\")\n",
        "print(\"3: トークン数を数える\")\n",
        "print(\"4: 出力フォルダをダウンロード(.zip)\")\n",
        "print(\"5: 出力フォルダを削除\")\n",
        "mode = input(\"番号を入力してください: \").strip()\n",
        "\n",
        "# --- 必要なパラメータを先に全て入力 ---\n",
        "hf_params = {}\n",
        "civitai_params = {}\n",
        "\n",
        "model_list_H = ['stablediffusionapi/eleet-model',\n",
        "              'stablediffusionapi/brav6',\n",
        "              'Vsukiyaki/ShiratakiMix',\n",
        "              'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "]\n",
        "\n",
        "model_list_C = [[\"https://civitai.com/api/download/models/28100?type=Model&format=SafeTensor&size=full&fp=fp16\",\"Anime Pastel Dream\",False],\n",
        "                [\"https://civitai.com/api/download/models/1410435?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\"WAI-NSFW-illustrious-SDXL v:11.0\",True]\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "if mode == \"1\":\n",
        "  hf_params[\"need_pipe\"] = input(\"pipelineをインストールしますか？ (y/n): \").strip().lower() == \"y\"\n",
        "  if hf_params[\"need_pipe\"]:\n",
        "    hf_params[\"model_id\"] = input(\"HuggingFaceのモデルIDを入力（例: runwayml/stable-diffusion-v1-5）: \").strip()\n",
        "  hf_params[\"submode\"] = input(\"生成モードを選択（1: text2img, 2: img2img）: \").strip()\n",
        "  hf_params[\"prompt\"] = input(\"プロンプトを入力: \").strip()\n",
        "  hf_params[\"negative_prompt\"] = input(\"ネガティブプロンプトを入力 : \").strip()\n",
        "  hf_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  hf_params[\"steps\"] = int(input(\"ステップ数（例: 70）: \"))\n",
        "  hf_params[\"guidance\"] = float(input(\"guidance scale（例: 7.5）: \"))\n",
        "  if hf_params[\"submode\"] == \"2\":\n",
        "    hf_params[\"strength\"] = float(input(\"strength (例: 0.75) : \"))\n",
        "    hf_params[\"image_path\"] = input(\"初期画像のパスを入力してください（img2img用）: \")\n",
        "\n",
        "  \"\"\"\n",
        "  while True:\n",
        "    print(\"修正する入力がある場合は\")\n",
        "    print(\"num:10\")\n",
        "    print(\"のように入力してください。\")\n",
        "    print(\"ない場合は空欄\")\n",
        "    corr = input(\"入力: \")\n",
        "    if corr == \"\":\n",
        "      break\n",
        "    corr = corr.split(\":\")\n",
        "    if corr[0] in hf_params:\n",
        "      hf_params[corr[0]] = corr[1]\n",
        "    elif corr[0] == \"drive_use\" and not corr[1] == \"y\":\n",
        "      drive_use = False\n",
        "    elif corr[0] == \"drive_use\" or corr[0] == \"drive_save\":\n",
        "      from google.colab import drive\n",
        "      import os\n",
        "      # マウントポイント\n",
        "      mount_point = '/content/drive'\n",
        "      drive_use = True\n",
        "      # Driveがマウントされているか確認\n",
        "      if not os.path.exists(mount_point):\n",
        "        print(\"Google Driveに接続されていません。接続しますか？ (y/n)\")\n",
        "        connect_drive = input().strip().lower()\n",
        "        if connect_drive == 'y':\n",
        "          drive.mount(mount_point)\n",
        "          print(\"Google Driveに接続しました。\")\n",
        "        else:\n",
        "          print(\"Google Driveへの接続をスキップしました。\")\n",
        "          drive_use = False\n",
        "      if corr[1] == \"\":\n",
        "        drive_use = False\n",
        "      if corr[0] == \"drive_use\":\n",
        "        print(\"保存する「ディレクトリ」のパスを入力してください。\")\n",
        "        print(\"(例: /content/drive/MyDrive/Colab Notebooks/your_dir)\")\n",
        "        print(\"※指定したディレクトリに追加で階層が生成されます(timestamp)。\")\n",
        "        print(\"保存しない場合は空欄で\")\n",
        "        drive_save = input(\"Path or Empty: \")\n",
        "        if drive_save == \"\":\n",
        "          drive_use = False\n",
        "        else:\n",
        "          drive_use = True\n",
        "\n",
        "      if corr[0] == \"drive_save\" and drive_use:\n",
        "        drive_save = corr[1]\n",
        "  \"\"\"\n",
        "\n",
        "elif mode == \"2\":\n",
        "  print(\"--- CivitAI モデルの状況は？ ---\")\n",
        "  print(\"1: まだ何もしていない（DLも変換もしていない）\")\n",
        "  print(\"2: safetensorsファイルのみアップロード済み（変換が必要）\")\n",
        "  print(\"3: 変換済みでそのまま使える\")\n",
        "  civitai_params[\"status\"] = input(\"番号を入力してください: \").strip()\n",
        "  #civitai_params[\"model_name\"] = input(\"保存先モデル名（例: models）: \").strip()\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    for k in range(len(model_list_C)):\n",
        "      print(f\"{k+1} : {model_list_C[k][1]}\")\n",
        "    civitai_params[\"url\"] = input(\"CivitAIのモデル/LoRA ダウンロードURL: \").strip()\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \").strip().lower() == \"y\"\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "  elif civitai_params[\"status\"] == \"2\":\n",
        "    print(\"モデルは\")\n",
        "    print(\"「/content/models/downloaded_model.safetensors」\")\n",
        "    print(\"に保存してください。\")\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \").strip().lower() == \"y\"\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "  else:\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \")\n",
        "  civitai_params[\"need_pipe\"] = input(\"pipelineをインストールしますか？ (y/n): \").strip().lower() == \"y\"\n",
        "  civitai_params[\"submode\"] = input(\"生成モードを選択 (1: text2img, 2: img2img) : \").strip()\n",
        "  civitai_params[\"prompt\"] = input(\"プロンプトを入力してください: \")\n",
        "  civitai_params[\"negative_prompt\"] = input(\"ネガティブプロンプトを入力 : \").strip()\n",
        "  civitai_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  civitai_params[\"steps\"] = int(input(\"ステップ数（例: 70）: \"))\n",
        "  if civitai_params[\"submode\"] == \"2\":\n",
        "    civitai_params[\"strength\"] = float(input(\"strength (例: 0.75)(img2img用) : \"))\n",
        "    civitai_params[\"image_path\"] = input(\"初期画像のパスを入力してください（例: /content/your_img.png）: \")\n",
        "  civitai_params[\"lora_path\"] = input(\"LoRAを使用する場合はpathを(使わない場合は無入力)\")\n",
        "  if civitai_params[\"lora_path\"] == \"\":\n",
        "    civitai_params[\"lora_path\"] = None\n",
        "\n",
        "\n",
        "elif mode == \"3\":\n",
        "  token_prompt = input(\"プロンプトを入力してください（トークン数確認）: \").strip()\n",
        "\n",
        "elif mode == \"4\":\n",
        "  print(\"少々お待ちください。\")\n",
        "\n",
        "elif mode == \"5\":\n",
        "  confirm_delete = input(\"本当にoutputフォルダを削除しますか？ (y/n): \").strip().lower()\n",
        "\n",
        "# --- 必要なinstallはここで実行（全てのinput終了後） ---\n",
        "print(\"インストールを開始します...\")\n",
        "!pip install diffusers transformers accelerate safetensors\n",
        "\n",
        "\n",
        "# --- 各モード実行 ---\n",
        "if mode == \"1\":\n",
        "  from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "  from PIL import Image\n",
        "  import torch\n",
        "  import os\n",
        "  from datetime import datetime, timedelta\n",
        "  jst = datetime.utcnow() + timedelta(hours=9)\n",
        "  timestamp = jst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  timeDir = {\n",
        "      \"y\":jst.strftime(\"%Y\"),\n",
        "      \"m\":jst.strftime(\"%m\"),\n",
        "      \"d\":jst.strftime(\"%d\"),\n",
        "      \"t\":jst.strftime(\"%H-%M-%S\")\n",
        "      }\n",
        "  torch_dtype = torch.float16\n",
        "\n",
        "  if 'model_id' not in hf_params:\n",
        "    hf_params[\"model_id\"] = \"unknown\"\n",
        "  if hf_params[\"need_pipe\"]:\n",
        "    if hf_params[\"submode\"] == \"1\":\n",
        "      pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        hf_params[\"model_id\"],\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None  # Safe checkを無効に\n",
        "      )\n",
        "      pipe = pipe.to(\"cuda\")  # GPUが必要です\n",
        "    else:\n",
        "      pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        hf_params[\"model_id\"],\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None\n",
        "      )\n",
        "      pipe = pipe.to(\"cuda\")\n",
        "  if hf_params[\"submode\"] != \"1\":\n",
        "    init_image = Image.open(hf_params[\"image_path\"]).convert(\"RGB\").resize((512, 512))\n",
        "  for k in range(hf_params[\"num\"]):\n",
        "    if hf_params[\"submode\"] == \"1\":\n",
        "\n",
        "      image = pipe(hf_params[\"prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   guidance_scale=hf_params[\"guidance\"],\n",
        "                   added_cond_kwargs={}).images[0]\n",
        "    else:\n",
        "      #init_image = Image.open(hf_params[\"image_path\"]).convert(\"RGB\").resize((512, 512))\n",
        "      image = pipe(prompt=hf_params[\"prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   image=init_image,\n",
        "                   strength=hf_params[\"strength\"],\n",
        "                   guidance_scale=hf_params[\"guidance\"]).images[0]\n",
        "    if drive_use:\n",
        "      save_dir = os.path.join(\n",
        "          drive_save,\n",
        "          timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "          timeDir[\"d\"],\n",
        "          timeDir[\"t\"],\n",
        "          hf_params[\"prompt\"][0:20],\n",
        "      )\n",
        "\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "      # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "      if k == 0:\n",
        "        with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "          if hf_params[\"submode\"] == \"1\":\n",
        "            f.write(\"t2i\\n\\n\")\n",
        "          else:\n",
        "            f.write(\"i2i\\n\\n\")\n",
        "          f.write(\"Model:\\nHugging Face / \"+hf_params[\"model_id\"]+\"\\n\\n\")\n",
        "          f.write(\"Prompt:\\n\" + hf_params[\"prompt\"] + \"\\n\\n\")\n",
        "          f.write(\"Negative Prompt:\\n\" + hf_params[\"negative_prompt\"])\n",
        "\n",
        "    else:\n",
        "      os.makedirs(\"output/\"+timestamp+\"/\"+hf_params[\"prompt\"][0:10], exist_ok=True)\n",
        "      filename = f\"output/\"+timestamp+\"/\"+hf_params[\"prompt\"][0:10]+\"/\"+str(k+1)+\".png\"\n",
        "      image.save(filename)\n",
        "  print(\"画像を保存しました\")\n",
        "\n",
        "elif mode == \"2\":\n",
        "  import os\n",
        "  import torch\n",
        "  import re\n",
        "  from datetime import datetime, timedelta\n",
        "  jst = datetime.utcnow() + timedelta(hours=9)\n",
        "  timestamp = jst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  timeDir = {\n",
        "      \"y\":jst.strftime(\"%Y\"),\n",
        "      \"m\":jst.strftime(\"%m\"),\n",
        "      \"d\":jst.strftime(\"%d\"),\n",
        "      \"t\":jst.strftime(\"%H-%M-%S\")\n",
        "      }\n",
        "  if civitai_params[\"submode\"] == \"2\":\n",
        "    from PIL import Image\n",
        "    from IPython.display import display\n",
        "\n",
        "\n",
        "  base_dir = \"/content/models\"\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "  download_path = \"/content/models/downloaded_model.safetensors\"\n",
        "\n",
        "  #※Driveのinfo.txtに書くための変数!!\n",
        "  modelName = \"unknown\"\n",
        "\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    regex = r'([0-9]+)'\n",
        "    regex2 = r'#(\\d+)'\n",
        "    if bool(re.match(regex, civitai_params['url'])):\n",
        "      num = int(civitai_params['url'])-1\n",
        "      civitai_params['url'] = model_list_C[num][0]\n",
        "      modelName = model_list_C[num][1]\n",
        "    else:\n",
        "      match = re.fullmatch(regex2, civitai_params['url'])\n",
        "      if match:\n",
        "        modelName = \"model_id:\" + match.group(1)\n",
        "        civitai_params['url'] = 'https://civitai.com/api/download/models/'+match.group(1)\n",
        "\n",
        "\n",
        "    model_url = civitai_params[\"url\"]\n",
        "\n",
        "    print(model_url)\n",
        "\n",
        "    print(f\"Downloading Checkpoint model to {download_path}...\")\n",
        "    !wget -O {download_path} \"{model_url}\"\n",
        "    print(f\"Download of safetensorFile complete!\")\n",
        "\n",
        "    # Checkpointモデルのパスを記録\n",
        "    checkpoint_path = download_path\n",
        "  lora_path = civitai_params[\"lora_path\"] # LoRAはダウンロードしないとNone\n",
        "\n",
        "\n",
        "  if civitai_params[\"status\"] == \"1\" or civitai_params[\"status\"] == \"2\":\n",
        "    if civitai_params[\"need_yaml\"]:\n",
        "      !wget -O /content/models/v1-inference.yaml \\\n",
        "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      #!wget -q https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-inference.yaml\n",
        "    if not civitai_params[\"sdxl\"]:\n",
        "      !mkdir /content/converted\n",
        "      !wget -O convert_original_stable_diffusion_to_diffusers.py \\\n",
        "      https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "      os.makedirs(base_dir, exist_ok=True)\n",
        "      !python convert_original_stable_diffusion_to_diffusers.py \\\n",
        "        --checkpoint_path ./models/downloaded_model.safetensors \\\n",
        "        --original_config_file ./models/v1-inference.yaml \\\n",
        "        --dump_path ./converted/diffusers_model \\\n",
        "        --from_safetensors\n",
        "\n",
        "  #pipe = None\n",
        "  if civitai_params[\"need_pipe\"]:\n",
        "    if civitai_params[\"sdxl\"]:\n",
        "      if civitai_params[\"submode\"] == \"1\":\n",
        "        from diffusers import StableDiffusionXLPipeline\n",
        "        pipe_civitai = StableDiffusionXLPipeline.from_single_file(\n",
        "            download_path,\n",
        "            torch_dtype=torch.float16, # fp16モデルなので必須\n",
        "            use_safetensors=True,      # safetensors形式であることを明示\n",
        "            safety_checker=None\n",
        "        ).to(\"cuda\")\n",
        "      else:\n",
        "        from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "        from PIL import Image\n",
        "        import torch\n",
        "\n",
        "        pipe_civitai = StableDiffusionXLImg2ImgPipeline.from_single_file(\n",
        "            download_path,\n",
        "            torch_dtype=torch.float16,\n",
        "            use_safetensors=True,\n",
        "            safety_checker=None,\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "      # VRAM節約と高速化のための設定（非常に重要）\n",
        "      #pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "      # 最も重要なVRAM節約策：モデルの一部をCPUにオフロード\n",
        "      # VRAMが16GB以下のGPUでは、SDXLを動かすためにほぼ必須です\n",
        "      pipe_civitai.enable_model_cpu_offload()\n",
        "    else:\n",
        "      from diffusers import StableDiffusionPipeline\n",
        "      #pipe = StableDiffusionPipeline.from_pretrained(base_dir, torch_dtype=torch.float16).to(\"cuda\")\n",
        "      pipe_civitai = StableDiffusionPipeline.from_pretrained(\n",
        "          \"/content/converted/diffusers_model\",\n",
        "          torch_dtype=torch.float16,\n",
        "          use_safetensors=False,\n",
        "          safety_checker=None\n",
        "        ).to(\"cuda\")\n",
        "    # パイプラインを作成した直後に以下を追加します\n",
        "    if lora_path:\n",
        "      pipe_civitai.load_lora_weights(lora_path, use_safetensors=True)\n",
        "\n",
        "\n",
        "  if civitai_params[\"submode\"] == \"1\":\n",
        "  #pipe.enable_xformers_memory_efficient_attention()\n",
        "    for k in range(civitai_params[\"num\"]):\n",
        "      image = pipe_civitai(prompt=civitai_params[\"prompt\"],\n",
        "          negative_prompt=civitai_params[\"negative_prompt\"],\n",
        "          num_inference_steps=civitai_params[\"steps\"]\n",
        "      ).images[0]\n",
        "      if drive_use:\n",
        "        save_dir = os.path.join(\n",
        "            drive_save,\n",
        "            timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "            timeDir[\"d\"],\n",
        "            timeDir[\"t\"],\n",
        "            civitai_params[\"prompt\"][0:20],\n",
        "        )\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "        # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "        if k == 0:\n",
        "          with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"t2i\\n\\n\")\n",
        "            if civitai_params[\"sdxl\"]:\n",
        "              f.write(\"Model:\\nCivitAI(SDXL) / \"+modelName+\"\\n\\n\")\n",
        "            else:\n",
        "              f.write(\"Model:\\nCivitAI / \"+modelName+\"\\n\\n\")\n",
        "            f.write(\"Prompt:\\n\" + civitai_params[\"prompt\"] + \"\\n\\n\")\n",
        "            f.write(\"Negative Prompt:\\n\" + civitai_params[\"negative_prompt\"])\n",
        "\n",
        "      else:\n",
        "        os.makedirs(\"output/t2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10], exist_ok=True)\n",
        "        image.save(\"output/t2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10]+\"/\"+str(k+1)+\".png\")\n",
        "    print(\"画像を保存しました。\")\n",
        "    #print(\"画像を保存しました: output/t2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10])\n",
        "  else:\n",
        "    init_image = Image.open(civitai_params[\"image_path\"]).convert(\"RGB\").resize((1024, 1024))\n",
        "    #display(init_image)\n",
        "    for k in range(civitai_params[\"num\"]):\n",
        "      image = pipe_civitai(prompt=civitai_params[\"prompt\"],\n",
        "          negative_prompt=civitai_params[\"negative_prompt\"],\n",
        "          image=init_image,\n",
        "          num_inference_steps=civitai_params[\"steps\"],\n",
        "          strength=civitai_params[\"strength\"],\n",
        "      ).images[0]\n",
        "      if drive_use:\n",
        "        save_dir = os.path.join(\n",
        "            drive_save,\n",
        "            timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "            timeDir[\"d\"],\n",
        "            timeDir[\"t\"],\n",
        "            civitai_params[\"prompt\"][0:20],\n",
        "        )\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "        # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "        if k == 0:\n",
        "          with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"i2i\\n\\n\")\n",
        "            if civitai_params[\"sdxl\"]:\n",
        "              f.write(\"Model:\\nCivitAI(SDXL) / \"+modelName+\"\\n\\n\")\n",
        "            else:\n",
        "              f.write(\"Model:\\nCivitAI / \"+modelName+\"\\n\\n\")\n",
        "            f.write(\"Prompt:\\n\" + civitai_params[\"prompt\"] + \"\\n\\n\")\n",
        "            f.write(\"Negative Prompt:\\n\" + civitai_params[\"negative_prompt\"])\n",
        "      else:\n",
        "        os.makedirs(\"output/i2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10], exist_ok=True)\n",
        "        image.save(\"output/i2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10]+\"/\"+str(k+1)+\".png\")\n",
        "    print(\"画像を保存しました。\")\n",
        "    #print(\"画像を保存しました: output/i2i/\"+timestamp+\"/\"+civitai_params[\"prompt\"][0:10])\n",
        "\n",
        "elif mode == \"3\":\n",
        "  from transformers import CLIPTokenizer\n",
        "  tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "  tokens = tokenizer(token_prompt)[\"input_ids\"]\n",
        "  print(f\"トークン数: {len(tokens)}\")\n",
        "\n",
        "elif mode == \"4\":\n",
        "  import shutil\n",
        "  from google.colab import files\n",
        "\n",
        "  # 圧縮したいディレクトリのパス\n",
        "  folder_path = '/content/output'\n",
        "  zip_filename = folder_path + '.zip'\n",
        "\n",
        "  # ディレクトリを zip 形式で圧縮\n",
        "  shutil.make_archive(folder_path, 'zip', folder_path)\n",
        "\n",
        "  # Colab にダウンロードリンクを表示\n",
        "  files.download(zip_filename)\n",
        "\n",
        "\n",
        "elif mode == \"5\":\n",
        "  import shutil\n",
        "  if confirm_delete == \"y\" and os.path.exists(\"output\"):\n",
        "    shutil.rmtree(\"output\")\n",
        "    print(\"outputフォルダを削除しました\")\n",
        "  else:\n",
        "    print(\"キャンセルされました\")\n"
      ],
      "metadata": {
        "id": "JtmjWZm4Yeqj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c7a0ad4f5744c6b975b4be03450aea1",
            "b91a8602ac444a72a01f0f40342cb5a7",
            "6afad3f66c4d49f0b1a286bf74ad6f77",
            "a50f70a22cd941808d77fe9884b02430",
            "20c858dcfa87437aa063fa537d38ad19",
            "a511493796154924abb34ff95315461b",
            "e0f7ff44349e43aca7a9f258eec938c6",
            "51248ebc8a5f4b5dbec279ea8ea74350",
            "1875646c2316432eba13625910a5541a",
            "5c06e0067e6b4387a59a0d81e4d46576",
            "87d0ba28054b4da5aec4c11c777cd284"
          ]
        },
        "outputId": "579ac847-78ea-4d47-b23a-0c1fe82593b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Driveを使用すると\n",
            "画像が一枚生成されるごとに保存されます。\n",
            "Google Driveを使用しますか？ (y/n): y\n",
            "保存する「ディレクトリ」のパスを入力してください。\n",
            "(例: /content/drive/MyDrive/Colab Notebooks/your_dir)\n",
            "※指定したディレクトリに追加で階層が生成されます(timestamp)。\n",
            "保存しない場合は空欄で\n",
            "Path or Empty: /content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/generated\n",
            "=== モード選択 ===\n",
            "1: Hugging Faceで画像生成\n",
            "2: CivitAI（モデルDL / safetensors変換）\n",
            "3: トークン数を数える\n",
            "4: 出力フォルダをダウンロード(.zip)\n",
            "5: 出力フォルダを削除\n",
            "番号を入力してください: 2\n",
            "--- CivitAI モデルの状況は？ ---\n",
            "1: まだ何もしていない（DLも変換もしていない）\n",
            "2: safetensorsファイルのみアップロード済み（変換が必要）\n",
            "3: 変換済みでそのまま使える\n",
            "番号を入力してください: 3\n",
            "モデルはSDXLですか？ (y/n): y\n",
            "pipelineをインストールしますか？ (y/n): n\n",
            "生成モードを選択 (1: text2img, 2: img2img) : 1\n",
            "プロンプトを入力してください: anime, 1girl, cute, on the bed, golden fox ears, sex, golden hair, many sticky and white liquid from crotch, blush, open mouth, tongue, a fox tail, see-through, looking at viewer, many pussy juice, nipples, cowgirl position, medium breasts, arched back,climax,masterpiece\n",
            "ネガティブプロンプトを入力 : real, low quality, pure, monotonous, boringly\n",
            "生成する画像の枚数 : 20\n",
            "ステップ数（例: 70）: 70\n",
            "LoRAを使用する場合はpathを(使わない場合は無入力)\n",
            "インストールを開始します...\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.31.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/70 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c7a0ad4f5744c6b975b4be03450aea1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!rm -r \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/generated_IMG\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UdcIrfXd4UtI"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}